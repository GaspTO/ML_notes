Paper: [***Intriguing properties of neural networks***](https://arxiv.org/pdf/1312.6199.pdf)

It's also the paper introduces the notion of adversarial attacks


# Overview
Pretty much looks at the images that activate the most some of the last layer's hidden units and, to compare, it creates random vectors and finds the images that maximize the weighted average of those hidden units.

And they find out is that you can find similarity in the images of both, which means that one hidden unit alone does not mean anything particular, as a random vector can be associated with input patterns.
